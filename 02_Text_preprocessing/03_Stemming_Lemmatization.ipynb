{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stemming and Lemmatization\n",
    "\n",
    "\"Lemmatization(표제어추출)\" and \"stemming(어간추출)\" are themethoeds reducing number of words\n",
    "\n",
    "## 1. Lemmatization\n",
    "\n",
    "Lemmatization sperate stem with affixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\boba-\n",
      "[nltk_data]     research\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "n=WordNetLemmatizer()\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print([n.lemmatize(w) for w in words])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result seems it lemmatized words. But some words like \"dy\" lost there meaning.\n",
    "\n",
    "WordNetLemmatizer has input of word class so we can reveal the word \"dies\" is used for verb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'die'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('dies', 'v')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lemmatization preserves word class information but stemming doesn't\n",
    "\n",
    "## 2. Stemming\n",
    "\n",
    "Stemming kind of simplified version of morphological study.\n",
    "Also it is task cutting end of words.\n",
    "So it is not that delicated task so result of stemming can't be found on dictionary.\n",
    "\n",
    "One of famous stemming algorithm is Porter Algorithm\n",
    "\n",
    "porter algorithm has rules like lower examples.\n",
    "* alize -> al\n",
    "* ance -> X\n",
    "* ical -> ic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "s = PorterStemmer()\n",
    "words=['formalize', 'allowance', 'electricical']\n",
    "print([s.stem(w) for w in words])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stemming is faster than lemmatization. Porter algorithm is\n",
    "sophisticated and accurate so it is best choice to use it for stemming.\n",
    "\n",
    "There is Lancaster Stemmer algorithm in NLTK.\n",
    "\n",
    "You can use both algorithm when you preprocess your corpus\n",
    " and find out which algorithm fits for your case.\n",
    "\n",
    "### difference between stemming and lemmatization\n",
    "\n",
    "Stemming\n",
    "* am → am\n",
    "* the going → the go\n",
    "* having → hav\n",
    "\n",
    "Lemmatization\n",
    "* am → be\n",
    "* the going → the going\n",
    "* having → have\\\n",
    "\n",
    "## 한국어의 특징 (For Korean)\n",
    "\n",
    "한국어의 용언은 어간과 어미로 나뉘는데 바뀌지 않는 어미는 분리하기 쉽지만. (잡 + 다)\n",
    "바뀌는 어미는 분리하기 어렵다. (긋다, 그어)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2491b1d0",
   "language": "python",
   "display_name": "PyCharm (NLP_study)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}